{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQlPxvRYBqCEaGQ7WNXJrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreH2002/Photo_cropping_and_AI_SuperResolution/blob/main/ESRGAN_MODEL_MOBILE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initial setup"
      ],
      "metadata": {
        "id": "iZQmLrHz2Klq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qY2x3vpBbJ-c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ConvBlock class\n",
        "class ConvBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size=3, stride=1, padding=\"same\", activation=\"leakyrelu\"):\n",
        "        super().__init__()\n",
        "        self.conv = layers.Conv2D(filters, kernel_size, strides=stride, padding=padding)\n",
        "\n",
        "        if activation == \"leakyrelu\":\n",
        "            self.activation = layers.LeakyReLU(0.2)\n",
        "        elif activation == \"relu\":\n",
        "            self.activation = layers.ReLU()\n",
        "        elif activation == \"prelu\":\n",
        "            self.activation = layers.PReLU(shared_axes=[1, 2])\n",
        "        elif activation is None:\n",
        "            self.activation = None\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown activation: {activation}\")\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0PGUbmaKiszE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Residual Dense Block\n",
        "class ResidualDenseBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters=64, growth_channels = 32, num_layers=5):\n",
        "    super().__init__()\n",
        "    self.blocks = []\n",
        "    for i in range(num_layers):\n",
        "      out_channels = growth_channels if i < num_layers - 1 else filters\n",
        "      self.blocks.append(ConvBlock(out_channels, activation =\"leakyrelu\"))\n",
        "\n",
        "  def call(self, x):\n",
        "    inputs = x\n",
        "    concat_feat = x\n",
        "    for block in self.blocks:\n",
        "      out = block(concat_feat)\n",
        "      concat_feat = tf.concat([concat_feat, out], axis=-1)\n",
        "    return inputs + 0.2 * out"
      ],
      "metadata": {
        "id": "j0mw2XO3TdJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Residual-In-Residual Dense Block\n",
        "class RRDB(layers.Layer):\n",
        "  def __init__(self, filters=64, growth_channels = 32):\n",
        "    super().__init__()\n",
        "    self.rdb1 = ResidualDenseBlock(filters, growth_channels)\n",
        "    self.rdb2 = ResidualDenseBlock(filters, growth_channels)\n",
        "    self.rdb3 = ResidualDenseBlock(filters, growth_channels)\n",
        "\n",
        "  def call(self, x):\n",
        "    inputs = x\n",
        "    out = self.rdb1(x)\n",
        "    out = self.rdb2(x)\n",
        "    out = self.rdb3(x)\n",
        "    return inputs + 0.2 * out"
      ],
      "metadata": {
        "id": "97K-R1Dc0QT4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleBlock(layers.Layer):\n",
        "  def __init_(self, filters, scale=2):\n",
        "    super().__init__()\n",
        "    self.conv = ConvBlock(filters *\n",
        "     (scale ** 2), kernel_size=3, activation =None)\n",
        "    self.scale = scale\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    #rearrange channels into spatial resolution\n",
        "    x = tf.nn.depth_to_space(x, block_size = self.scale)\n",
        "    x = tf.nn.leaky_relu(x, alpha=0.2)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "hEkfU9W1YSKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "class Generator(layers.layer):\n",
        "  def __init__(self, num_rrdb=23, filters=64, growth_channels=32, scale = 4):\n",
        "    super().__init__()\n",
        "    self.conv_first = ConvBlock(filters, kernel_size=3, activation=None)\n",
        "\n",
        "    #RRDB trunk\n",
        "    self.rrdb_blocks = [RRDB(filters, growth_channels) for _ in range(num_rrdb)]\n",
        "    self.trunk_conv = ConvBlock(filters, kernel_size=3, activation=None)\n",
        "\n",
        "    #Upsampling\n",
        "    upsample_blocks = []\n",
        "    for _ in range(scale // 2):\n",
        "      upsample_blocks.append(UpsampleBlock(filters, scale=2))\n",
        "    self.upsample_blocks = upsample_blocks\n",
        "\n",
        "    self.hr_conv = ConvBlock(filters, kernel_size=3, activation=\"leakyrelu\")\n",
        "    self.conv_last = ConvBlock(3, kernel_size =3, activation = None) #output RGB\n",
        "\n",
        "  def call(self, x):\n",
        "    features = self.conv_first(x)\n",
        "\n",
        "    trunk = features\n",
        "    for rrdb in self.rrdb_blocks:\n",
        "      trunk = rrdb(trunk)\n",
        "    trunk = self.trunk_conv(trunk)\n",
        "\n",
        "    features = features + trunk #global residual\n",
        "\n",
        "    #Upsampling\n",
        "    for up in self.upsample_blocks:\n",
        "      features = up(features)\n",
        "\n",
        "    features = self.hr_conv(features)\n",
        "    out = self.conv_last(features)\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "1u_XzZj20UQN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Stage 1/just generator\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "QoJK6kRu2Ghi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.\n",
        "\n",
        "\n",
        "#Prepare paired data\n",
        "\n",
        "#Sample an HR image.\n",
        "\n",
        "#Randomly crop an HR patch of size hr_size (e.g., 512×512).\n",
        "\n",
        "#Downscale it by the scale factor (e.g., ×4) to get LR patch lr_size = hr_size/scale (128×128).\n",
        "\n",
        "#(Optional) Add real-world degradations (blur, noise, JPEG) to mimic old iPhone photos.\n",
        "\n",
        "#Apply random flips/rotations consistently to LR/HR.\n",
        "\n",
        "#Normalize both LR and HR to the same range (e.g., [-1,1] or [0,1]).\n"
      ],
      "metadata": {
        "id": "xnOus1o-0e8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.\n",
        "\n",
        "#Forward pass (Generator)\n",
        "\n",
        "#Feed LR → Generator → get SR."
      ],
      "metadata": {
        "id": "mpO5zWX52gj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.\n",
        "\n",
        "#Compute losses\n",
        "\n",
        "#Content loss (L1): L1(SR, HR).\n",
        "\n",
        "#Perceptual loss (optional but recommended):\n",
        "\n",
        "#Pass SR and HR through a fixed VGG feature extractor.\n",
        "\n",
        "#Compute L1/L2 in one or more feature layers (e.g., conv3_4, conv5_4).\n",
        "\n",
        "#(Optional) Regularizers: TV loss, edge-aware loss, color consistency."
      ],
      "metadata": {
        "id": "7JiyQJZJ201F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.\n",
        "\n",
        "#Aggregate loss\n",
        "\n",
        "#L_total = λc * L1 + λp * L_perc (+ λtv * L_tv …)\n",
        "\n",
        "#Choose small λp at first; tune empirically."
      ],
      "metadata": {
        "id": "blvEKTrZ4dcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.\n",
        "\n",
        "#Backprop + update\n",
        "\n",
        "#Compute gradients w.r.t. generator params.\n",
        "\n",
        "#(Optional) Gradient clipping (e.g., global norm).\n",
        "\n",
        "#Optimizer step (e.g., Adam).\n",
        "\n",
        "#(Optional) EMA update of generator weights for more stable checkpoints."
      ],
      "metadata": {
        "id": "W80Qa7Zh6DQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6.\n",
        "\n",
        "#Log + schedule\n",
        "\n",
        "#Track running loss; periodically compute PSNR/SSIM on a validation set.\n",
        "\n",
        "#Apply LR schedule (e.g., cosine, step decay, or ReduceLROnPlateau)."
      ],
      "metadata": {
        "id": "ZpbdZTmo6Dhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.\n",
        "\n",
        "#Checkpoint\n",
        "\n",
        "#Save best generator by val metric (PSNR/SSIM) and latest checkpoint."
      ],
      "metadata": {
        "id": "cgrVbvzt6Dnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.\n",
        "\n",
        "#Repeat for epochs\n",
        "\n",
        "#Stop when content/perceptual losses plateau and visuals look clean (no GAN yet)."
      ],
      "metadata": {
        "id": "X0oamoXm6Dtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training stage 2/adding discriminator"
      ],
      "metadata": {
        "id": "GFSNFGSE9CLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "\n",
        "B) Adversarial Fine-Tuning (Full ESRGAN)\n",
        "\n",
        "Goal: add realistic texture with a discriminator while preserving fidelity from phase A.\n",
        "\n",
        "Initialize\n",
        "\n",
        "Load the best pretrained Generator from Phase A.\n",
        "\n",
        "Initialize Discriminator (patch-based).\n",
        "\n",
        "Keep VGG feature extractor frozen.\n",
        "\n",
        "Prepare paired data (same as A)\n",
        "\n",
        "HR crop → LR via degradation pipeline; augment; normalize.\n",
        "\n",
        "Update Discriminator (D)\n",
        "\n",
        "Forward:\n",
        "\n",
        "SR_detached = G(LR) (stop gradient).\n",
        "\n",
        "D_real = D(HR), D_fake = D(SR_detached).\n",
        "\n",
        "Loss (choose one):\n",
        "\n",
        "LSGAN: (D_real - 1)^2 + (D_fake)^2\n",
        "or\n",
        "\n",
        "BCE: -log(σ(D_real)) - log(1 - σ(D_fake))\n",
        "or\n",
        "\n",
        "Relativistic average (ESRGAN paper), if you prefer.\n",
        "\n",
        "(Optional) Regularization:\n",
        "\n",
        "R1 gradient penalty on real images, or spectral norm in D.\n",
        "\n",
        "Backprop + update D.\n",
        "\n",
        "Update Generator (G)\n",
        "\n",
        "Forward (fresh SR): SR = G(LR).\n",
        "\n",
        "Loss components:\n",
        "\n",
        "Content (L1): L1(SR, HR) (keeps identity/structure).\n",
        "\n",
        "Perceptual: VGG feature loss between SR and HR (sharpness).\n",
        "\n",
        "Adversarial (G-side):\n",
        "\n",
        "For LSGAN: (D(SR) - 1)^2\n",
        "\n",
        "For BCE: -log(σ(D(SR)))\n",
        "\n",
        "(Relativistic variant if using it in D.)\n",
        "\n",
        "(Optional) Feature matching: L1 between intermediate D features for SR vs HR (stabilizes textures).\n",
        "\n",
        "(Optional) TV/edge regularizers to control noise.\n",
        "\n",
        "Aggregate:\n",
        "\n",
        "L_G = λc*L1 + λp*L_perc + λadv*L_adv (+ λfm*L_featmatch + …)\n",
        "\n",
        "Use small λadv to avoid over-texturing faces.\n",
        "\n",
        "Backprop + update G.\n",
        "\n",
        "(Optional) EMA update of G.\n",
        "\n",
        "Stabilization tactics (each iteration or periodically)\n",
        "\n",
        "Alternate k steps of D per 1 step of G (e.g., k=1).\n",
        "\n",
        "Use mixed precision for speed; keep loss scaling safe.\n",
        "\n",
        "Monitor D/G losses; if D becomes too strong, reduce k or apply dropout/augmentations in D.\n",
        "\n",
        "Validation + early stopping\n",
        "\n",
        "On a val set, compute PSNR/SSIM and do a visual panel review (textures vs artifacts).\n",
        "\n",
        "Track identity preservation on faces (manually or with a face embedding distance if available).\n",
        "\n",
        "Early stop when textures improve without identity drift.\n",
        "\n",
        "Checkpointing\n",
        "\n",
        "Save both G and D regularly.\n",
        "\n",
        "Also save EMA-smoothed G—often best for inference.\n",
        "\n",
        "Export\n",
        "\n",
        "Freeze the final/EMA Generator.\n",
        "\n",
        "(Optional) Run a calibration pass for INT8 post-training quantization using a few hundred LR samples.\n",
        "\n",
        "Convert to TFLite (FP16 or INT8) for mobile deployment.\n",
        "'''"
      ],
      "metadata": {
        "id": "mKYfXBQ59HPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}